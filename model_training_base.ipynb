{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oPu5NKHhvaD"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EADbnSf9hvaD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiPhaeaniF2-",
    "outputId": "21f63272-3e9f-4953-fc25-f895dd547033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "N_nCrkg9iLKS",
    "outputId": "e6415684-cb42-48e6-be04-817546e3df62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.... literally stuck in the 4th dimension...</td>\n",
       "      <td>0</td>\n",
       "      <td>02/18/2021, 18:44:59</td>\n",
       "      <td>1362473201490681856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Looking for a map of #COVID19 vaccine provider...</td>\n",
       "      <td>1</td>\n",
       "      <td>02/24/2021, 19:35:52</td>\n",
       "      <td>1364660332308889602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We need bold action -- not only to end the pan...</td>\n",
       "      <td>2</td>\n",
       "      <td>02/18/2021, 18:42:04</td>\n",
       "      <td>1362472468401840129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Literally looks like a cult...</td>\n",
       "      <td>0</td>\n",
       "      <td>02/24/2021, 19:37:01</td>\n",
       "      <td>1364660621850136582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is what “school reopening” looks like. Re...</td>\n",
       "      <td>0</td>\n",
       "      <td>02/18/2021, 18:45:10</td>\n",
       "      <td>1362473247829336071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>voidedOrc36584 allofDuty Brother, chances are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>02/18/2021, 18:43:46</td>\n",
       "      <td>1362472893901377545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>harliekirk11 Hey you dumb fuck, do a little re...</td>\n",
       "      <td>0</td>\n",
       "      <td>03/07/2021, 22:21:34</td>\n",
       "      <td>1368688300958056448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Would you really make this appeal if you had p...</td>\n",
       "      <td>2</td>\n",
       "      <td>02/24/2021, 19:44:57</td>\n",
       "      <td>1364662620893175808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spin Sensation ujeeb_R88 has joined Peshawar Z...</td>\n",
       "      <td>1</td>\n",
       "      <td>02/18/2021, 18:44:30</td>\n",
       "      <td>1362473080719826953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Early on in the pandemic, covid-19 outbreaks d...</td>\n",
       "      <td>0</td>\n",
       "      <td>02/18/2021, 18:40:19</td>\n",
       "      <td>1362472027353980931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                DATA  ...           Unnamed: 3\n",
       "0       .... literally stuck in the 4th dimension...  ...  1362473201490681856\n",
       "1  Looking for a map of #COVID19 vaccine provider...  ...  1364660332308889602\n",
       "2  We need bold action -- not only to end the pan...  ...  1362472468401840129\n",
       "3                     Literally looks like a cult...  ...  1364660621850136582\n",
       "4  This is what “school reopening” looks like. Re...  ...  1362473247829336071\n",
       "5  voidedOrc36584 allofDuty Brother, chances are ...  ...  1362472893901377545\n",
       "6  harliekirk11 Hey you dumb fuck, do a little re...  ...  1368688300958056448\n",
       "7  Would you really make this appeal if you had p...  ...  1364662620893175808\n",
       "8  Spin Sensation ujeeb_R88 has joined Peshawar Z...  ...  1362473080719826953\n",
       "9  Early on in the pandemic, covid-19 outbreaks d...  ...  1362472027353980931\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_location = '/content/drive/My Drive/SYSC 4907 COVID & Deep Learning/Model Training/'\n",
    "training_data_file = 'FINAL_COMBINED_3_TRAIN.xlsx'\n",
    "training_data_path = data_file_location + training_data_file\n",
    "training_data = pd.read_excel(training_data_path)\n",
    "training_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "vFV4iukUqI6i",
    "outputId": "60949168-1c75-4503-904f-c82e7a27bb29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why should anyone have to hack for this techno...</td>\n",
       "      <td>1</td>\n",
       "      <td>02/18/2021, 18:40:36</td>\n",
       "      <td>1362472099185590273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did they test positive for COVID?</td>\n",
       "      <td>1</td>\n",
       "      <td>03/07/2021, 17:52:06</td>\n",
       "      <td>1368620488063324166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our EY COVID-19 Response Group supporting #Thu...</td>\n",
       "      <td>2</td>\n",
       "      <td>02/18/2021, 18:45:07</td>\n",
       "      <td>1362473236781498370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joe Biden's Coronavirus Coordinator just said ...</td>\n",
       "      <td>0</td>\n",
       "      <td>03/07/2021, 17:52:30</td>\n",
       "      <td>1368620587027927042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Tanzania: Vice President uluhuSamia with no f...</td>\n",
       "      <td>1</td>\n",
       "      <td>02/18/2021, 18:45:07</td>\n",
       "      <td>1362473237414821890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COVID-19 hospitalizations dropped to 1,137 Thu...</td>\n",
       "      <td>1</td>\n",
       "      <td>02/18/2021, 18:41:21</td>\n",
       "      <td>1362472286624751618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Look like it nuh sink ina your cerebrum yet......</td>\n",
       "      <td>0</td>\n",
       "      <td>03/07/2021, 17:52:26</td>\n",
       "      <td>1368620569386758149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>*spring 2023* PRINCETON, N.J. — The Ivy League...</td>\n",
       "      <td>1</td>\n",
       "      <td>02/18/2021, 18:45:05</td>\n",
       "      <td>1362473227163996164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It’s not just the industry trifecta\" of chicke...</td>\n",
       "      <td>0</td>\n",
       "      <td>02/24/2021, 19:36:47</td>\n",
       "      <td>1364660566824992769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fuck Johnathan Corona, all the homies hate Joh...</td>\n",
       "      <td>0</td>\n",
       "      <td>02/18/2021, 18:45:25</td>\n",
       "      <td>1362473312505356289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                DATA  ...           Unnamed: 3\n",
       "0  Why should anyone have to hack for this techno...  ...  1362472099185590273\n",
       "1                  Did they test positive for COVID?  ...  1368620488063324166\n",
       "2  Our EY COVID-19 Response Group supporting #Thu...  ...  1362473236781498370\n",
       "3  Joe Biden's Coronavirus Coordinator just said ...  ...  1368620587027927042\n",
       "4  #Tanzania: Vice President uluhuSamia with no f...  ...  1362473237414821890\n",
       "5  COVID-19 hospitalizations dropped to 1,137 Thu...  ...  1362472286624751618\n",
       "6  Look like it nuh sink ina your cerebrum yet......  ...  1368620569386758149\n",
       "7  *spring 2023* PRINCETON, N.J. — The Ivy League...  ...  1362473227163996164\n",
       "8  It’s not just the industry trifecta\" of chicke...  ...  1364660566824992769\n",
       "9  Fuck Johnathan Corona, all the homies hate Joh...  ...  1362473312505356289\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_file = 'FINAL_COMBINED_3_TEST.xlsx'\n",
    "test_data_path = data_file_location + test_data_file\n",
    "test_data = pd.read_excel(test_data_path)\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlphFfhkDRdu",
    "outputId": "6c697cfb-6e09-4b35-c782-5fd2f68c5258"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1672\n",
       "1    1425\n",
       "2     895\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.LABEL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adZjR0rdjwtR",
    "outputId": "f48027e7-0fc6-4499-e9d2-eb3fd98652b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    229\n",
       "1    208\n",
       "2     76\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.LABEL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vANVyq4fyFCb",
    "outputId": "ef71d472-bcfd-4fcd-d36a-8e760bb17589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.... literally stuck in the 4th dimension...'\n",
      " 'Looking for a map of #COVID19 vaccine providers? Find our interactive map here: #InThisTogetherOhio'\n",
      " 'We need bold action -- not only to end the pandemic, but to rebuild our health care system.'\n",
      " 'Literally looks like a cult...'\n",
      " 'This is what “school reopening” looks like. Reopening schools before every teacher is vaccinated is sanctioning mass death.']\n",
      "3992 Training sequences\n",
      "[0 1 2 0 0]\n",
      "513 Testing sequences\n"
     ]
    }
   ],
   "source": [
    "subset = training_data[['DATA', 'LABEL']]\n",
    "x_train = subset['DATA'].to_numpy()\n",
    "y_train = subset['LABEL'].to_numpy()\n",
    "subset = test_data[['DATA', 'LABEL']]\n",
    "x_val = subset['DATA'].to_numpy()\n",
    "y_val = subset['LABEL'].to_numpy()\n",
    "print(x_train[0:5])\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(y_train[0:5])\n",
    "print(len(x_val), \"Testing sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSBJdRk9hvaD"
   },
   "source": [
    "## Implement a Transformer block as a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JASykSzVhvaE"
   },
   "source": [
    "## Implement embedding layer\n",
    "\n",
    "Two seperate embedding layers, one for tokens, one for token index (positions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJhIuZy-Oul8"
   },
   "outputs": [],
   "source": [
    "def tokenize(inp):\n",
    "  i = 0\n",
    "  for entry in inp:\n",
    "    inp[i] = tf.keras.preprocessing.text.one_hot(inp[i], n=25000, lower=True)\n",
    "    i = i + 1\n",
    "  return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt5p1UC2MJQO"
   },
   "outputs": [],
   "source": [
    "x_train = tokenize(x_train)\n",
    "x_val = tokenize(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLbToILkUQ2Y"
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1aJP5IehvaE"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "118FINqShvaE"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.2):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3_vh_gnhvaF"
   },
   "outputs": [],
   "source": [
    "vocab_size = 25000  # Only consider the top 25k words\n",
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "INP = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x1 = embedding_layer(INP)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x2 = transformer_block(x1)\n",
    "x3 = layers.GlobalAveragePooling1D()(x2)\n",
    "x4 = layers.Dropout(0.1)(x3)\n",
    "layer_dense = layers.Dense(20, activation=\"relu\")(x4)\n",
    "x_drop = layers.Dropout(0.2)(layer_dense)\n",
    "OUT = layers.Dense(3, activation=\"softmax\")(x_drop)\n",
    "\n",
    "model = keras.Model(inputs=INP, outputs=OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5Xj79S4WD4V",
    "outputId": "89831781-43df-444a-dad1-36cbe7441a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 40)]              0         \n",
      "_________________________________________________________________\n",
      "token_and_position_embedding (None, 40, 32)            801280    \n",
      "_________________________________________________________________\n",
      "transformer_block_1 (Transfo (None, 40, 32)            10656     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 812,659\n",
      "Trainable params: 812,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGzZjI9yhvaF"
   },
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Avkeob1bhvaF"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(opt, loss='sparse_categorical_crossentropy', metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-po09m2IqW9",
    "outputId": "aee87aa3-667b-4546-dfd8-6f2091e70670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 5s 25ms/step - loss: 1.2313 - sparse_categorical_accuracy: 0.2807 - val_loss: 1.0317 - val_sparse_categorical_accuracy: 0.5283\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 1.0678 - sparse_categorical_accuracy: 0.4237 - val_loss: 0.9986 - val_sparse_categorical_accuracy: 0.5341\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 1.0493 - sparse_categorical_accuracy: 0.4416 - val_loss: 0.9809 - val_sparse_categorical_accuracy: 0.5673\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 1.0208 - sparse_categorical_accuracy: 0.4953 - val_loss: 0.9733 - val_sparse_categorical_accuracy: 0.5575\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.9832 - sparse_categorical_accuracy: 0.5277 - val_loss: 0.9331 - val_sparse_categorical_accuracy: 0.6218\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.9621 - sparse_categorical_accuracy: 0.5609 - val_loss: 0.9079 - val_sparse_categorical_accuracy: 0.6413\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.9039 - sparse_categorical_accuracy: 0.6085 - val_loss: 0.9134 - val_sparse_categorical_accuracy: 0.5887\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.8368 - sparse_categorical_accuracy: 0.6494 - val_loss: 0.9133 - val_sparse_categorical_accuracy: 0.6160\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 0.7641 - sparse_categorical_accuracy: 0.7022 - val_loss: 0.8395 - val_sparse_categorical_accuracy: 0.6433\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.7488 - val_loss: 0.8730 - val_sparse_categorical_accuracy: 0.6374\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model training base",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
